# Word2Vec

one-hot encoding
- cannot find similarity between words
- very sparse data

# Similarity based representations
similar 'contexts'

### Context
surrounding words : 2-left and 2-right

# 2 Models
## CBOW
predict target words form context-words
`P(every|words|in|sentences)`
average --> smooth

## Skip-gram
predict context-words from the target word
**choose the method**
`p(pair|word)`

# Trainiing the model
## log-likelihood

# Negative Sampling

# Linear Relationshipin word2vec
- syntactically : Vsingular ~ Vplural
- semantically : Vking-Vman ~ Vqueen-Vwoman



